---
title: Nanopore barcoding analysis report
output:
  bookdown::html_document2:
    toc_depth: 1
    theme: flatly
  bookdown::pdf_document2:
    toc_depth: 1
    extra_dependencies: ['cochineal', 'inconsolata']
mainfont: Cochineal
monofont: InconsolataN
linkcolor: blue
papersize: a4
---

\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(targets)
library(dplyr)
library(ggplot2)
library(patchwork)

ggplot_theme <- function(base_size=10, ...) {
  theme_minimal(base_size, ...) + theme(
    text = element_text(),
    panel.background = element_rect(colour = NA),
    plot.title = element_text(size = rel(1.1)),
    panel.border = element_rect(
      color = 'black',
      fill = NA,
      linetype = 1,
      size = 0.4
    ),
    axis.title = element_text(size = rel(1)),
    axis.text = element_text(colour = 'black', size = rel(1)),
    axis.line = element_line(colour = "black", linewidth = 0.3),
    axis.ticks = element_line(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.spacing = unit(3, 'pt'),
    strip.background = element_blank(),
    strip.text = element_text(size = rel(1)),
    legend.title = element_text(size = rel(1)),
    legend.text = element_text(size = rel(1)),
    legend.key = element_rect(colour = NA),
    legend.key.height = unit(0.8, 'lines'),
  )
}

options(readr.show_col_types=F)
pander::panderOptions('missing', '')
pander::panderOptions('table.alignment.default', 'left')
pander::panderOptions('table.style', 'multiline')
pander::panderOptions('table.split.table', Inf)
theme_set(ggplot_theme())
```

```{css}
h1 { font-size: 22px; }
h2 { font-size: 18px; }
h3 { font-size: 14px; }
blockquote { font-size: 14px; }
```

```{r}
config <- tar_read(config)
```

Run: *`r config$analysis_dir`*

Date: *`r format(Sys.time(), '%d %B, %Y')`*

Analyzed with *[DadaNanoBC](https://github.com/markschl/DadaNanoBC) v`r as.character(packageVersion('DadaNanoBC'))`*

# The workflow (in short)

1)  Search the primers and short sample indexes (located up-/downstream of the primer sequences)
2)  Infer the barcode sequences with [DADA2](https://benjjneb.github.io/dada2) and/or fixed-threshold clustering (for low-coverage variants), align and infer the consensus
3)  Auto-assign the taxonomy and compare with provided taxon names to validate and check for contamination.
4)  Compare with already known sequences (if present)
5)  Export summary table, which can be further manually curated

See [documentation](https://markschl.github.io/DadaNanoBC) for more details.

# Input/configuration

```{r}
amplicon_primers <- tar_read(amplicon_primers)
amplicons <- names(amplicon_primers)
```

The input following files are needed:

* Base-called sequences (`reads.fastq.gz`)
* Metadata file (`meta.xlsx`)
* Configuration file (*config.yaml*)

The contents of *config.yaml*:

``` yaml
`r xfun::file_string(file.path(analysis_dir, 'config.yaml'))`
```

## Samples


The run has `r nrow(amplicon_primers)` amplicon(s) with the following sample numbers:

```{r sample-tab, render=pander::pander}
tar_read(sample_tab) %>% 
  group_by(amplicon) %>% 
  summarise(
    `# samples` = n(),
    `# taxon provided` = sum(!is.na(taxon)),
    `# with known sequence` = sum(!is.na(known_sequence)),
    .groups = 'drop'
  )
```

> *Note*: primers are searched in the order that amplicons appear in the sample sheet. With *nested amplicons*, the shorter one should be placed at the end.

## Primers

The primers are defined in the *primers* sheet of the *meta.xlsx* input file. Here is a summary of the primers and the attached sample indexes.

```{r render=pander::pander}
# (we don't use map_dfr to avoid the purrr dependency)
idxdist = bind_rows(lapply(amplicon_primers, function(amp_pr) {
  bind_rows(lapply(amp_pr, function(d) {
    dst = adist(d$index)
    tibble(
      primer = names(d$primer),
      seq = d$primer,
      `index length` = d$index_len,
      dist = dst[lower.tri(dst, F)]
    )
  }), .id='direction')
}), .id='amplicon')

idxdist.summary = idxdist %>% 
  # make sure primers are in order
  mutate(across(c(amplicon, primer), ~ factor(.x, unique(.x)))) %>% 
  group_by(amplicon, primer, seq, `index length`) %>% 
  summarise(
    `min. index dist.` = min(dist),
    `median dist.` = median(dist),
    `max. dist.` = max(dist),
    .groups = 'drop'
  )
idxdist.summary
```

```{r}
overall_min_idx_dist = min(idxdist.summary$`min. index dist.`)
stopifnot(config$demultiplex$idx_max_diffs < overall_min_idx_dist)
```

The forward and reverse sample indexes have a length of `r paste(unique(idxdist.summary[['index length']]), collapse=' / ')` bp and a minimum edit distance of `r min(idxdist.summary[['min. index dist.']])` (see also Figure \@ref(fig:idxdist)). The maximum allowed number of sequencing errors in barcodes is `r (config$demultiplex$idx_max_diffs)` (`idx_max_diffs` in *config.yaml*). This value should always be *smaller than the minimum distance* between any sample index).

> *Note*: Using a lower `idx_max_diffs` threshold reduces false assignments of reads to samples, but also leads to less sequences being included in the analysis. On the other hand, an increased error tolerance increases the read count. You can check the unused barcode combinations (*unspecific* in below figures) for any "background noise".

(ref:idxdist) Distribution of pairwise edit distances between sample indexes

```{r idxdist, fig.width=4, fig.height=1+1.5*length(amplicons), fig.cap='(ref:idxdist)'}
ggplot(idxdist, aes(dist)) +
  geom_histogram(binwidth=1, fill = '#a6bddb', color='#2b8cbe') +
  facet_wrap( ~ paste(amplicon, direction), ncol=2, scales='free') + 
  scale_x_continuous(breaks=0:10) +
  scale_y_continuous(expand=expansion(mult=c(0, .05))) +
  labs(x='Edit distance between sample indexes',
       y='count') +
  theme(strip.text.y = element_text(angle = 0, hjust = 0))
```

# De-multiplexing

Steps:

-   Search for the primers (up to `r 100 * config$demultiplex$primer_max_err` % error rate)
-   Search for the sample indexes next to the primers (max. `r config$demultiplex$idx_max_diffs` differences)
-   Trim primers, filter by quality (max. `r config$demux$error_threshold` expected errors) and distribute into different files by barcode (de-multiplex)

## Primer trimming

```{r search-primers}
primer_stats <- tar_read(trim_demux)$trim_stats

# stats
tail_len_mean <- primer_stats$position %>% 
  group_by(amplicon, dir) %>% 
  summarise(tail_len = weighted.mean(pos - 1, count),
            .groups='drop')

amplen_mean <- primer_stats$amplicon_len %>% 
  group_by(amplicon) %>%
  filter(category == 'regular') %>% 
  summarise(mean_len = weighted.mean(length, count))
max_mean_len = max(na.omit(amplen_mean$mean_len))

count_stats <- primer_stats$counts %>% 
  group_by(amplicon, category) %>% 
  summarise(count = sum(count), .groups='drop')

qual_stats <- primer_stats$quality %>% 
  mutate(
    primer_mis_grp = ifelse(!is.na(primer_mis) & primer_mis < 4, as.character(primer_mis), '4+'),
    idx_mis_grp = ifelse(!is.na(idx_mis) & primer_mis < 2, as.character(primer_mis), '2+')
  )
```

The following table shows the average trimmed amplicon length and the total read numbers for each amplicon. Also, there are always small tails at the ends before the primer starts (assuming `--no-trim` Dorado option, which is necessary).

```{r trim-stats, render=pander::pander}
full_join(
  amplen_mean %>% 
    mutate(mean_len = paste(round(mean_len, 1), 'bp')) %>% 
    rename(`avg. amplicon length` = mean_len),
  tail_len_mean %>% 
    group_by(amplicon) %>% 
    summarise(tail_len = ifelse(
        all(is.na(tail_len)),
        NA,
        paste(paste(round(tail_len, 1), collapse=' / '), 'bp')
      ),
      .groups='drop'
    ) %>% 
    rename(`avg. tail length` = tail_len),
  'amplicon'
) %>% 
  mutate(amplicon = factor(amplicon, amplicons)) %>% 
  arrange(amplicon) %>% 
  left_join(count_stats %>%
              filter(category == 'valid amplicon') %>% 
              mutate(count = scales::label_number(accuracy=0.01, scale_cut = scales::cut_si(""))(count)) %>% 
              select(amplicon, `# trimmed reads` = count),
            'amplicon')
```

Usuall, a small part of the reads has tail lengths around the mean fragment length (or multiples of it) due to the presence of concatenated PCR products.

(ref:tail-stats) (**not shown**) Distribution of the primer trimmed tail lengths (*note the non-linear scale*)

```{r tail-stats, eval=FALSE, fig.width=6.7, fig.height=3, fig.cap='(ref:tail-stats)', warning=F}
ggplot(primer_stats$position, aes(pos - 1)) +
  geom_density(aes(weight=count), fill='#a6bddb', color='#2b8cbe', adjust=.1) +
  facet_grid(dir ~ amplicon, scales='free') +
  scale_y_sqrt(breaks = 10^(-4:0), expand=expansion(mult=c(0, .05))) +
  scale_x_continuous(limits=c(0, 1.4*max_mean_len), expand=expansion()) +
  guides(fill=guide_none()) +
  labs(x='Tail length (bp)', y='Density') +
  theme(strip.text.y=element_text(angle=0))
```

Trimmed reads are therefore checked for the presence of any primer sequence and removed if any was found. The average length of these fragments is usually longer than the mean length (Figure \@ref(fig:len-stats)).

(ref:len-stats) Distribution of trimmed fragment lengths (top panel), and fragment lengths for putative concatenated artifacts (bottom) containing primer sequences, which were removed.

```{r len-stats, fig.width=6.7, fig.height=3, fig.cap='(ref:len-stats)', warning=FALSE}
d <- primer_stats$amplicon_len %>% 
  filter(!is.na(count))
ggplot(d, aes(length, fill=category, color=category)) +
  geom_density(aes(weight=count), adjust=.1) +
  facet_grid(category ~ amplicon, scales='free') +
  scale_y_continuous(expand=expansion(mult=c(0, .05))) +
  scale_x_continuous(limits=c(0, 2.5*max_mean_len), expand=expansion()) +
  labs(x='Trimmed fragment length (bp)', y='Density', fill=NULL) +
  scale_fill_manual(values=c(regular='#a6bddb', 'contains primer'='lightgrey'), guide='none') +
  scale_color_manual(values=c(regular='#2b8cbe', 'contains primer'='darkgrey'), guide='none') +
  theme(strip.text.y=element_text(angle=0))
```

## Quality filtering

The quality filtering should remove highly errorneous sequencing reads, while still retaining enough reads for inferring the barcode sequences.

According to Figure \@ref(fig:mismatch-stats), reads with many primer or sample index mismatches also tend to have lower quality scores. With the current settings, reads with \>`r config$demux$error_threshold` errors (`error_threshold` setting) and reads shorter than `r config$demultiplex$min_barcode_length` bp (`min_barcode_length` setting) are discarded. Figure \@ref(fig:readstats) helps with determining the impact of the settings on the number of reads passing the filter.

(ref:mismatch-stats) Mismatch statistics/quality statistics, based on the quality scores from the base-called FASTQ file. (a) Comparison of index/primer mismatches, colored by average read quality; (b/c) Distribution of expected errors per read, colored by primer/index mismatches.

```{r mismatch-stats, fig.width=6.7, fig.height=3.5, fig.cap='(ref:mismatch-stats)', warning=FALSE}
# remove amplicons without data
p1 <- qual_stats %>%
  group_by(idx_mis, primer_mis) %>% 
  summarise(exp_err = weighted.mean(exp_err, count), .groups='drop') %>% 
  ggplot(aes(idx_mis, primer_mis, fill=exp_err)) +
  geom_tile() +
  scale_x_continuous(breaks=0:20) +
  scale_y_continuous(breaks=0:20) +
  scale_fill_distiller(palette='Spectral',
                       guide=guide_colorbar(title.position='top')) +
  theme(legend.position='bottom') +
  labs(x='Index mismatches', y='Primer mismatches',
       fill='Expected sequencing errors')

count_plot_cfg <- list(
  scale_y_continuous(labels = scales::label_number(scale_cut = scales::cut_short_scale()),
                     expand = expansion(mult = c(0, 0.05))),
  scale_fill_brewer(palette='Set1',
                       guide=guide_legend(title.position='top', ncol=3)),
  theme(legend.position='bottom',
        axis.text.x=element_text(angle=90, vjust=0.5, hjust=1)),
  labs(x='Exp. sequencing errors', y='Count')
  
)

p2 <- qual_stats %>%
  group_by(exp_err=cut(exp_err, c(-1:5, Inf)), primer_mis_grp) %>% 
  summarise(count = sum(count), .groups='drop') %>% 
  ggplot(aes(exp_err, count, fill=as.factor(primer_mis_grp))) +
  geom_col() +
  count_plot_cfg +
  labs(fill='Primer mismatches')

p3 <- qual_stats %>%
  group_by(exp_err=cut(exp_err, c(-1:5, Inf)), idx_mis_grp) %>% 
  summarise(count = sum(count), .groups='drop') %>% 
  ggplot(aes(exp_err, count, fill=as.factor(idx_mis_grp))) +
  geom_col() +
  count_plot_cfg +
  labs(fill='Index mismatches')

(p1 | p2 | p3) +
  plot_layout(widths=c(3, 3, 3)) +
  plot_annotation(tag_levels='a')
```

(ref:readstats) Read counts by category

```{r readstats, fig.width=6.7, fig.height=1.8+0.2*length(amplicons), fig.cap='(ref:readstats)'}
d <- primer_stats$counts %>% 
  group_by(category, valid) %>% 
  summarise(count = sum(count), .groups='drop')

ee <- qual_stats %>% 
  filter(!is.na(idx_mis) & !is.na(primer_mis)) %>% 
  group_by(amplicon, category = paste(cut(exp_err, c(-1:5, Inf)), 'errors')) %>% 
  summarise(
    count = sum(count),
    .groups = 'drop'
  )

stopifnot(sum(d$count[d$valid]) == sum(ee$count))

invalid_lab <- 'invalid'
d.ee <- bind_rows(
  d %>% 
    filter(!valid) %>% 
    mutate(group = invalid_lab),
  ee %>% 
    mutate(valid = TRUE) %>% 
    rename(group = amplicon)
) %>% 
  mutate(group = factor(group, c(invalid_lab, amplicons)))

ggplot(d.ee, aes(group, count, fill=category)) +
  geom_col(position = position_stack(reverse=TRUE)) +
  labs(x=NULL, y='count') +
  coord_flip() +
  scale_y_continuous(labels=scales::label_number(scale_cut = scales::cut_si("")),
                     expand=expansion(mult=c(0, .05))) +
  theme(legend.position='bottom') +
  scale_fill_hue(direction=-1, h.start=270) +
  labs(fill=NULL) +
  guides(fill = guide_legend(ncol=4))
```

# Infer barcodes

Before the DADA2 denoising, it is necessary to determine how the quality scores in the sequencing reads correlate with the substitution error rates. Usually, the relationship looks fairly log-linear, although there can be a plateau/increase at Q \> 40 (Figure \@ref(fig:dada2-errplot)).

(ref:errplot) Q-scores vs. error frequencies learned by DADA2

```{r dada2-errplot, fig.width=4.5, fig.height=3.8, fig.cap='(ref:errplot)', warning=FALSE}
dada_err <- tar_read(dada_err)
dada2::plotErrors(dada_err) +
  ggplot_theme()
```

From each of the de-multiplexed and filtered read files, a maximum of `r config$cluster$max_sample_depth` reads (`max_sample_depth` setting) are analyzed (Figure \@ref(fig:cluster-validation)a).

The DADA2 denoising method relies on presence of **at least a few error-free reads** in the filtered Nanopore data. This should usually be the case with recent (R10.4) sequencing data, and assuming that amplicons are not extremely long. Specifically, the proportion of singletons[^1] has to be lower than 100 % (Figure \@ref(fig:cluster-validation)b), as duplicated sequences are the most likely to represent the true barcode sequences in the sample, while singletons often contain sequencing errors.

[^1]: Singletons are sequences only present *once* in a sample (non-duplicated)

The barcode clustering procedure automatically checks the read duplication, and switches from DADA2 denoising to fixed-threshold clustering (*cluster_fixed* method in figures) if there are \< `r config$cluster$dada_min_identical` identical sequences or \< `r config$cluster$dada_min_n0` sequences without substitution errors (`dada_min_identical` and `dada_min_n0` settings). This is mostly the case for low-depth samples with < reads (Figure \@ref(fig:cluster-validation)b-d). In some cases, DADA2-denoised ASVs can be further split into two more or less equally abundant haplotypes (*dada_split* method in Figure \@ref(fig:cluster-validation)).

```{r}
seq_tab <- tar_read(cluster_seqtab_combined)
```

(ref:cluster-validation) Details on the clustering, colored by clustering method. (a) Analyzed read depth of samples (up to `r config$cluster$max_sample_depth` reads); (b) Proportion of singleton reads in relation to sequencing depth; (c) Number of *identical* sequences supporting the dominant sequence of the top taxon, compared to its abundance. (d) Number of *sequences without substitutions* (but possibly some InDels) = `n0` reported by DADA2, not known for other methods. The vertical line indicates a sequencing depth threshold of `r config$output$report$low_abund_threshold` reads (`low_abund_threshold` in *config.yaml*).

```{r cluster-validation, fig.width=6.7, fig.height=4.5, message=FALSE, warning=FALSE, fig.cap='(ref:cluster-validation)'}
method_cols = c(dada='#1f78b4', dada_split='#561fb4',
                cluster_fixed='#7fb128', 'other/unused indexes'='#ff7f00')

d <- seq_tab %>%
  filter(!is.na(seq_tab$top_n_mapped)) %>%
  mutate(
    method = factor(
      ifelse(
        grepl('sample', category),
        top_seq_method,
        'other/unused indexes'
      ),
      names(method_cols)
    ),
    top_seq_consensus_diffs = ifelse(grepl('dada', method), top_seq_consensus_diffs, NA)
  )

method_scale = function(dir='vertical') list(
  scale_color_manual(values = method_cols, 
                     guide = guide_legend(override.aes=list(size=2)),
                     drop = FALSE,
                     aesthetics = c('fill', 'color'),
                     name = 'Clustering method'),
  guides(fill = 'none'),
  theme(legend.direction=dir)
)

method_points <- list(
  geom_point(size=0.9, alpha=.6, show.legend = TRUE)
)

method_jitter <- list(
  geom_jitter(size=0.9, alpha=.6, show.legend = TRUE,
             height = 0.05, width=0)
)

depth_scale = list(
  geom_vline(xintercept = config$output$report$low_abund_threshold, color='grey'),
  scale_x_log10()
)

pabund = ggplot(d, aes(n_reads, fill=method)) +
  geom_histogram(binwidth = max(1, round(config$cluster$max_sample_depth / 50))) +
  scale_y_continuous(expand=expansion(mult=c(0, .05))) +
  method_scale('horizontal') +
  labs(x = 'Read depth in sample')

psingle = ggplot(d, aes(n_reads, singleton_frac,
                        color=method)) +
  geom_point(size=0.9, alpha=.6, show.legend = TRUE) +
  depth_scale +
  scale_y_continuous(labels = scales::label_percent()) +
  method_scale('horizontal') +
  labs(x='Read depth in sample',
       y='Proportion of singletons')

pident = ggplot(d, aes(top_n_mapped, top_max_identical,
                       color=method)) +
  method_points +
  scale_y_log10() +
  expand_limits(y=1) +
  depth_scale +
  method_scale('horizontal') +
  labs(x='Reads supporting the top sequence',
       y='identical seqs.')

pn0 = ggplot(d, aes(top_n_mapped, top_n0,
                    color=method)) +
  method_points +
  scale_y_log10() +
  expand_limits(y=1) +
  depth_scale +
  method_scale('horizontal') +
  labs(x='Reads supporting the top sequence',
       y='substitution-free seqs.\n(DADA2 n0)')

((pabund | psingle) /
  (pident | pn0) /
  guide_area()) +
  plot_layout(heights=c(4, 4, 1), guides='collect') +
  plot_annotation(tag_levels='a')
```

Ambiguous bases in the reported sequence mostly appear in low-depth samples, where fixed-threshold clustering is applied (*cluster_fixed* method) and no further separation of haplotypes is attempted (Figure \@ref(fig:cluster-validation2)a/b). These ambiguities may be further inspected manually. They may result from either an unresolved mix of different haplotypes or other sequence polymorphisms, or possibly from sequencing errors.

In rare cases, the alignment consensus does not match the inferred DADA2 ASV sequence (Figure \@ref(fig:cluster-validation2)c/d). These barcodes will have a *consensus-diffs* issue flag in the report, and the consensus sequence is reported (may be inspected manually, but usually the consensus should make sense).

(ref:cluster-validation2) (a/b) Distribution of the ambiguous base count in the top consensus sequence (\< `r config$cluster$consensus_threshold * 100` % in alignment having the same base). (c/d) Number of mismatches between the DADA2 ASV and the consensus sequence. The vertical line indicates a sequencing depth threshold of `r config$output$report$low_abund_threshold` reads (`low_abund_threshold` setting).

```{r cluster-validation2, fig.width=6.7, fig.height=4.5, message=FALSE, warning=FALSE, fig.cap='(ref:cluster-validation2)'}
group_limit = function(x, lim) factor(
  ifelse(x < lim, as.character(x), paste0(lim, '+')),
  levels = c(0:lim, paste0(lim, '+'))
)

d$cons_ambigs_ = group_limit(d$top_seq_consensus_ambigs, 10)
d$cons_diffs_ = group_limit(d$top_seq_consensus_diffs, 10)

amhist = ggplot(d, aes(cons_ambigs_, fill=method)) +
  geom_bar() +
  scale_y_continuous(expand=expansion(mult=c(0, .05))) +
  method_scale('horizontal') +
  labs(x = 'Ambiguities in consensus')

amdepth = ggplot(d, aes(n_reads, cons_ambigs_,
                        color=method)) +
  method_jitter +
  depth_scale +
  scale_y_discrete(expand=expansion(mult=c(.05, .1))) +
  method_scale('horizontal') +
  labs(x = 'Read depth', y = 'Consensus ambiguities')

d_dada = d[!is.na(d$top_seq_consensus_diffs),]
mhist = ggplot(d_dada, aes(cons_diffs_, fill=method)) +
  geom_bar() +
  scale_y_continuous(expand=expansion(mult=c(0, .05))) +
  method_scale('horizontal') +
  labs(x = 'DADA2 ASV vs. consensus mismatches')

mdepth = ggplot(d_dada, aes(n_reads, cons_diffs_,
                       color=method)) +
  method_jitter +
  scale_y_discrete(expand=expansion(mult=c(.05, .1))) +
  depth_scale +
  method_scale('horizontal') +
  labs(x = 'Read depth', y = 'ASV/cons. mismatches')

((amhist | amdepth) /
  (mhist | mdepth) /
  guide_area()) +
  plot_layout(widths=c(3, 5), heights=c(5, 5, 1), guides='collect') +
  plot_annotation(tag_levels='a')
```

# Haplotypes / polymorphism

The clustering procedure usually yields 1-2 abundant haplotype sequences from the target organism, and few rare/unspecific barcode sequences (Figure \@ref(fig:polymorphisms)a/b). In addition, there may be additional copies of the target barcode in the genomes. A fixed-threshold clustering at a similarity threshold of `r config$cluster$fixed_cluster_threshold * 100` % is done (`fixed_cluster_threshold` setting) to distinguish the target taxon from other organisms, which may also be present in the mix (contamination, symbiotic partner). If DNA was extracted from the tissue of multiple individuals, there might also be more than the two parental haplotypes. Polymorphisms with \< `r config$cluster$min_variant_freq * 100` % frequency in an organism group are removed (`min_variant_freq` setting).

The proportion of reads belonging to the final (probably specific) clusters is usually 50-100% at read depths \> 1000 due to how the DADA2 clustering works, but decreases with lower depths or if dominant contamination is present (Figure \@ref(fig:polymorphisms)c).

(ref:polymorphisms) (a/b) Distribution of sequence variant numbers for the top taxon in a sample; (c) Proportion of reads from the *top* organism group relative to the total analyzed read depth

```{r polymorphisms, fig.width=6.7, fig.height=4.5, message=FALSE, warning=FALSE, fig.cap='(ref:polymorphisms)'}
# TODO: investigate/filter contaminants present in (almost) every sample
d$n_seq_ = group_limit(d$top_n_reads, 10)
hhist = ggplot(d, aes(n_seq_, fill=method)) +
  geom_bar() +
  scale_y_continuous(expand=expansion(mult=c(0, .05))) +
  method_scale() +
  labs(x = 'barcode sequences per taxon')

hdepth = ggplot(d, aes(n_reads, n_seq_, color=method)) +
  method_jitter +
  depth_scale +
  method_scale() +
  scale_y_discrete(expand=expansion(mult=c(.05, .1))) +
  labs(x = 'Read depth', y = 'barcode sequences per taxon')

pspec = ggplot(d, aes(n_reads, target_cluster_frac,
                         color=method)) +
  method_points +
  depth_scale +
  scale_y_continuous(limits = c(0, 1), 
                     labels = scales::label_percent()) +
  method_scale() +
  labs(x = 'Read depth in sample', 
       y = '% reads from top taxon')

hhist + hdepth +
  pspec + guide_area() +
  plot_layout(ncol = 2, widths=c(5, 5), guide='collect') +
  plot_annotation(tag_levels='a')
```

# Taxonomic assignments

Taxonomic names are assigned with the the SINTAX algorithm using a bootstrap confidence threshold of `r config$taxonomy$confidence_threshold * 100` % (`confidence_threshold` setting). The composition per plate is shown in Figure \@ref(fig:tax-composition).

> **Caution**: these automatic sequence-based assignments are not guaranteed to be correct, it is recommended to further validate them, e.g. using BLAST.

```{r assign-taxonomy, include=FALSE}
seq_tab <- tar_read(taxonomy)$seq_tab
```

(ref:tax-composition) Taxonomic composition (based on barcode sequences) by amplicon and plate

```{r tax-composition, warning=FALSE, fig.width=6.7, fig.height=4, fig.cap='(ref:tax-composition)'}
abundant.lineages = names(head(sort(
  table(seq_tab$top_seq_short_lineage), TRUE
), 10))
d <- seq_tab %>%
  select(
    amplicon,
    plate,
    lineage = top_seq_short_lineage,
    nmatch = top_seq_matching_ranks,
    nmismatch = top_seq_mismatching_ranks,
    n_reads
  ) %>%
  filter(!is.na(plate)) %>%
  mutate(
    nrank = nmatch + nmismatch,
    tax_overlap = nmatch / nrank,
    lineage = factor(
      case_when(
        lineage %in% abundant.lineages ~ stringr::str_trunc(lineage, 50),
        n_reads > 0 ~ 'Other',
        n_reads == 0 ~ '(no sequence)'
      ),
      c(unique(
        stringr::str_trunc(abundant.lineages, 50)
      ), 'Other', '(no sequence)')
    )
  )

ggplot(d, aes(as.factor(plate), fill=lineage)) +
  geom_bar() +
  facet_grid(~ amplicon, scales='free', space='free') +
  scale_y_continuous(expand = expansion(mult=0)) +
  scale_fill_brewer(palette='Paired', guide=guide_legend(ncol=2)) +
  labs(x='Plate', fill=NULL) +
  theme(legend.position='bottom',
        legend.key.height=unit(0.8, 'lines'),
        axis.text.x=element_text(angle=45, hjust=1, vjust=1, size=7))
```

```{r results='asis'}
d.ov <- d %>% 
  filter(!is.na(nrank) & nrank >= 3) %>% 
  group_by(amplicon, plate) %>% 
  mutate(category = ifelse(mean(tax_overlap, na.rm=TRUE) > 0.5, 'looks ok', 'low overlap'))

if (nrow(d.ov) > 0) {
  cat('Figure \\@ref(fig:tax-overlap) summarizes the final taxonomic assignments. The taxonomic overlap (Figure \\@ref(fig:tax-overlap)b) should mostly be near 100% (bars on right side).\n')  
}
```

(ref:tax-overlap) Histograms showing the distribution of the taxonomic overlap between provided (e.g. morphological) and sequence-based taxonomic assignments (between 0 and 100%).

```{r tax-overlap, warning=FALSE, fig.width=6.7, fig.height=1 + 0.5 * sqrt(length(unique(seq_tab$plate))), fig.cap='(ref:tax-overlap)'}
if (nrow(d.ov) > 0) {
  ggplot(d.ov, aes(tax_overlap, fill=category)) +
    geom_histogram(binwidth=1/7) +
    facet_wrap(~ sprintf('%s / p%s', amplicon, plate), scales='free_y') +
    scale_y_continuous(expand = expansion(mult=c(0, 0.05))) +
    scale_fill_manual(values = c('looks ok'='#a6bddb', 'low overlap'='orange')) +
    coord_cartesian(xlim = c(0, 1)) +
    theme_void() +
    theme(legend.position='none',
          panel.spacing.x = unit(0, 'mm'),
          panel.border = element_rect(colour='black', size=0.5, fill=NA))
}
```

## Contamination

If taxonomic information was provided for the specimens (*taxon* column)

Any blacklisted taxa (`known_contaminants` setting) are directly flagged as contaminants, and other barcodes in the same sample are preferred.

Second, provided identifications (*taxon* column in metadata) are compared to the automatic taxonomic assignments. From this, a **taxonomic overlap** is calculated, which is the *proportion of matching ranks in the taxonomic lineages* (as far as names are defined at these levels). The lineages are retrieved from the [GBIF backbone](https://doi.org/10.15468/39omei) taxonomy.

A taxon is *automatically* classified as contaminant if there exists another sequence (group), which has a better taxonomic overlap with the morphological identification. The overlap is assumed to be better if...

- there exists a less abundant taxon with the correct kingdom
- a taxon has has at least *`r config$taxonomy$contam_rank_delta` more consistent (matching) taxonomic ranks* in the GBIF lineage compared to the top taxon (`contam_rank_delta` setting; undefined ranks excluded from the comparison).

> **note**: the ranking may sometimes be incorrect, or if contaminants are too related to the target taxon, they may not automatically be flagged; a **manual investigation of the report** is highly recommended.

`r if (any(seq_tab$has_contamination)) 'The following samples were found to contain dominant comtamination:\n'`

```{r render=pander::pander}
has_seqs = seq_tab$n_reads > 0
if (any(seq_tab$has_contamination)) {
  cont = seq_tab[seq_tab$has_contamination, ]
  cont$contaminants = sapply(cont$clustering, function(d) paste(unique(d$taxon[d$is_contaminant]), collapse=', '))
  rownames(cont) <- NULL
  cont %>% 
    select(sample, taxon, `correct taxon`=top_seq_taxon, contaminants) %>% 
    mutate(sample = stringr::str_trunc(sample, 30))
}
```

```{r results='asis'}
d <- seq_tab[!is.na(seq_tab$top_seq_known_seq_diffs),]
d$known_seq_diffs <- ifelse(d$top_seq_known_seq_diffs > 5, '5+', as.character(d$top_seq_known_seq_diffs))

if (nrow(d) > 0)
  cat('# Comparison to known sequences

In case of re-sequencing a specimen, there is the additional possibility of validating the result by calculating the number of differences (mismatches/gaps) (Figure \\@ref(fig:known-seq-diffs). Known sequences are inserted in the *known sequence* column of the samples metadata table. Inconsistent barcode sequences might be investigated further. It is still possible, that e.g. the provided Sanger sequences have errors as well, it is best to also investigate the chromatograms in case of inconsistencies.\n')
```

(ref:known-seq-diffs) Mismatches to already known sequences (in case of re-sequencing). The vertical red line indicates a critical sequencing depth threshold of `r config$output$report$low_abund_threshold` reads.

```{r known-seq-diffs, fig.width=5, fig.height=2.3, fig.cap='(ref:known-seq-diffs)'}
if (nrow(d) > 0) {
  h <- ggplot(d, aes(known_seq_diffs)) +
    geom_bar() +
    scale_y_continuous(expand = expansion(mult=c(0, 0.05))) +
    labs(x = 'Mismatches to\nknown sequence')
  
  p <- ggplot(d, aes(n_reads, known_seq_diffs)) +
    geom_point(size=0.8, color='#2b8cbe') +
    depth_scale +
    scale_y_discrete(expand = expansion(mult=c(0.05, 0.1))) +
    # scale_color_manual(values=cat.cols) +
    labs(x = 'Read depth', y = 'Mismatches to\nknown sequence') +
    theme(legend.position = 'right')
  
  h + p +
    plot_layout(ncol=2, widths=c(3, 5)) +
    plot_annotation(tag_levels='a')
}
```
